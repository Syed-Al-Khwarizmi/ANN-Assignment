{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Uy9Zh0scQhAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numba\n",
        "import keras\n",
        "import scipy.stats\n",
        "import seaborn as sns\n",
        "sns.set_context('notebook')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y0eCE3SFQkZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this code is required for Ex 1\n",
        "def display_image(im):\n",
        "    plt.imshow(im.reshape((28, 28)), cmap='gray_r')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "def fully_connected(ninputs, noutputs):\n",
        "    boundary = np.sqrt(6 / (ninputs + noutputs))\n",
        "    return np.random.uniform(-boundary, boundary, size=(ninputs, noutputs))\n",
        "\n",
        "def softmax(x):\n",
        "    expx = np.exp(x - x.max(axis=1, keepdims=True))\n",
        "    return expx / expx.sum(axis=1, keepdims=True)\n",
        "\n",
        "def accuracy(Yhat, Y):\n",
        "    return (Y.argmax(axis=1) == Yhat.argmax(axis=1)).mean()\n",
        "\n",
        "def cross_entropy(Yhat, Y):\n",
        "    ylogy = Y * np.log(Yhat)\n",
        "    return -ylogy.sum()\n",
        "\n",
        "def ReLU(X):\n",
        "    return np.maximum(X, 0)\n",
        "\n",
        "def dReLU(X):\n",
        "    return (X > 0).astype(float)\n",
        "\n",
        "def drop(X, keep_prob=1):\n",
        "    if keep_prob < 1:\n",
        "        X = X.copy() # we don't want to change X\n",
        "        keeps = np.random.rand(X.shape[1]) < keep_prob\n",
        "        # X.shape is (nsamples, nfeatures)\n",
        "        X[:, ~keeps] = 0 # ignore\n",
        "        X[:, keeps] *= (1/keep_prob) # normalize\n",
        "    return X\n",
        "\n",
        "def predict(Ws, X):\n",
        "    if X.ndim == 1:\n",
        "        X = X.reshape((1, -1))\n",
        "    return feed_forward(Ws, X, keep_prob=1)[-1]\n",
        "\n",
        "def display_prediction(idx):\n",
        "    prediction = predict(Ws, X_test[idx, :]).argmax()\n",
        "    print(prediction)\n",
        "    return display_image(X_test[idx])\n",
        "\n",
        "def loss(Ws, X, Y):\n",
        "    Yhat = predict(Ws, X)\n",
        "    return cross_entropy(Yhat, Y)\n",
        "\n",
        "def gradient_check(Ws, X, Y, Δ=1e-5):\n",
        "    dWs = back_propagation(Ws, X, Y, keep_prob=1)\n",
        "    Ws_ = [W.copy() for W in Ws]\n",
        "    \n",
        "    for i, (W_, dW_) in enumerate(zip(Ws_, dWs)):\n",
        "        print('W{}'.format(i+1))\n",
        "        for i in range(W_.shape[0]):\n",
        "            for j in range(W_.shape[1]):\n",
        "                dw = dW_[i, j]\n",
        "                W_[i,j] += Δ\n",
        "                loss1 = loss(Ws_, X, Y)\n",
        "                W_[i,j] -= 2*Δ\n",
        "                loss2 = loss(Ws_, X, Y)\n",
        "                W_[i,j] += Δ\n",
        "                dw_ = (loss1 - loss2) / (2 * Δ)\n",
        "                rel_error = abs(dw - dw_) / abs(dw + dw_)\n",
        "                if not np.isclose(dw_, dw):\n",
        "                    print(i, j, dw, dw_, rel_error)\n",
        "                \n",
        "def average(prev, curr, β):\n",
        "    return [β * p + (1 - β) * c for p, c in zip(prev, curr)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yO0FEukQmmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdamOptimizer:\n",
        "    def __init__(self, α=0.001, β1=0.9, β2=0.999, ε=1e-8):\n",
        "        self.α = α\n",
        "        self.β1 = β1\n",
        "        self.β2 = β2\n",
        "        self.ε = ε\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.t = 0\n",
        "    def send(self, gradients):\n",
        "        if self.m is None:\n",
        "            self.m = [0] * len(gradients)\n",
        "        if self.v is None:\n",
        "            self.v = [0] * len(gradients)\n",
        "        self.t += 1\n",
        "        αt = self.α * np.sqrt(1 - self.β2**self.t) / (1 - self.β1**self.t)\n",
        "        self.m = average(self.m, gradients, self.β1)\n",
        "        self.v = average(self.v, (g*g for g in gradients), self.β2)\n",
        "        updates = [-αt * mi / (np.sqrt(vi) + self.ε) for mi, vi in zip(self.m\n",
        "        , self.v)]\n",
        "        for upd in updates:\n",
        "            assert np.isfinite(upd).all()\n",
        "        return updates\n",
        "    def trainer(Ws, X, Y, optimizer, batch_size=50, keep_prob=1):\n",
        "        nsamples = X.shape[0]\n",
        "        batch = 0\n",
        "        while True:\n",
        "            # get next batch\n",
        "            start = (batch * batch_size) % nsamples\n",
        "            stop = start + batch_size\n",
        "            batch_idx = range(start, stop)\n",
        "            X_, Y_ = X[batch_idx, :], Y[batch_idx, :]\n",
        "            gradients = back_propagation(Ws, X_, Y_, keep_prob=keep_prob) # calculate gradients\n",
        "            ΔWs = optimizer.send(gradients) # calculate updatesfor W, ΔW in zip(Ws, ΔWs): # apply updates\n",
        "            W += ΔW\n",
        "            batch += 1\n",
        "            yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owNB6RTiQofq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "nsamples, width, height = X_train.shape\n",
        "nfeatures = width * height\n",
        "X_train = X_train.reshape(nsamples, nfeatures)\n",
        "X_test = X_test.reshape(-1, nfeatures)\n",
        "Y_train = keras.utils.to_categorical(Y_train)\n",
        "Y_test = keras.utils.to_categorical(Y_test)\n",
        "ncats = Y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0z3jVyTEQrs2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feed_forward(Ws, X, keep_prob=1):\n",
        "    X1 = X\n",
        "    W1, W2 = Ws\n",
        "    # hidden layer\n",
        "    Z1 = X1 @ W1\n",
        "    Z1 = drop(Z1, keep_prob=keep_prob)\n",
        "    X2 = ReLU(Z1)\n",
        "    # readout layer\n",
        "    Z2 = X2 @ W2\n",
        "    Yhat = softmax(Z2)\n",
        "    return [X1, Z1, X2, Z2, Yhat]\n",
        "  \n",
        "def back_propagation(Ws, X, Y, keep_prob=1):\n",
        "    W1, W2 = Ws\n",
        "    X1, Z1, X2, Z2, Yhat = feed_forward(Ws, X, keep_prob=keep_prob)\n",
        "    # readout layer\n",
        "    δ2 = Yhat - Y # prediction error, dJ/dYhat * dYhat/dZ2 (-1, ncats)\n",
        "    dW2 = X2.T @ δ2 # dJ/dW2 = δ2 * dZ2/dX2 = δ2 * X2\n",
        "    # hidden layer\n",
        "    δ1 = (δ2 @ W2.T) * dReLU(Z1) # δ1 = dJ/dX_2 = δ2 * dZ2/dX2 * dX2/dZ1 = δ2 * W2 * ReLU(Z1)\n",
        "    dW1 = X1.T @ δ1 # dJ/dW1 = δ1 * dZ1/dW1 = δ1 * X1\n",
        "    gradients = [dW1, dW2]\n",
        "    # sanity checks\n",
        "    assert len(gradients) == len(Ws), (len(gradients), len(Ws))\n",
        "    for dW, W in zip(gradients, Ws):\n",
        "        assert dW.shape == W.shape, (dW.shape, W.shape)\n",
        "    return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G48XG4t5Qw8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainer(Ws, X, Y, optimizer, batch_size=50, keep_prob=1):\n",
        "    nsamples = X.shape[0]\n",
        "    batch = 0\n",
        "    while True:\n",
        "        # get next batch\n",
        "        start = (batch * batch_size) % nsamples\n",
        "        stop = start + batch_size\n",
        "        batch_idx = range(start, stop)\n",
        "        X_, Y_ = X[batch_idx, :], Y[batch_idx, :]\n",
        "        gradients = back_propagation(Ws, X_, Y_, keep_prob=keep_prob) # calculate gradients\n",
        "        ΔWs = optimizer.send(gradients) # calculate updates\n",
        "        for W, ΔW in zip(Ws, ΔWs): # apply updates\n",
        "            W += ΔW\n",
        "        batch += 1\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8Rk1R8lQyw4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create model here\n",
        "nhidden = 100\n",
        "W1 = fully_connected(nfeatures, nhidden)\n",
        "W2 = fully_connected(nhidden, ncats)\n",
        "Ws = [W1, W2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gdJp8egCQ0iU",
        "colab_type": "code",
        "outputId": "80f132d7-e939-45a8-85df-0c2419797eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Before training, weak model, bad results, very unimpressive\n",
        "acc = accuracy(predict(Ws, X_test), Y_test) ###\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUrmmA0pQ4Sa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model works hard, joins some kind of a gym, and after some intense workout for many epochs, gets fully trained\n",
        "adm = AdamOptimizer()\n",
        "train = trainer(Ws, X_train, Y_train, optimizer=AdamOptimizer(), keep_prob=0.5)\n",
        "for batch in train:\n",
        "    if batch == 10 * nsamples // 50: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k2iwnr1IRaAu",
        "colab_type": "code",
        "outputId": "35179142-22c2-479d-ca96-4891db6112c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# After training, strong model, good results, looks dope!\n",
        "acc = accuracy(predict(Ws, X_test), Y_test)\n",
        "print(\"Accuracy ({:d}): {:.4f}\".format(batch, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy (12000): 0.9177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AyJzsOyuRxwp",
        "colab_type": "code",
        "outputId": "ef3d8365-4176-4f1a-cbc7-c190685a6b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Ex2 starts from here\n",
        "import keras\n",
        "print('Keras', keras.__version__)\n",
        "from keras import backend as K\n",
        "print('GPU:', K.tensorflow_backend._get_available_gpus())\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras 2.2.4\n",
            "GPU: ['/job:localhost/replica:0/task:0/device:GPU:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFR8H3qeR2H4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tmFb0CRR4oM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pre-processing and normalizing the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Resaping the data\n",
        "x_train = x_train.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Applying one-hot-encoding\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oM52wcLYopT",
        "colab_type": "code",
        "outputId": "cd491c3a-1327-4cc6-93de-6b978fb6d415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5kmD-ZlR6pk",
        "colab_type": "code",
        "outputId": "2d607f4f-4509-4890-c63d-47a2b014254e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's see the images\n",
        "i = np.random.randint(0, x_train.shape[0])\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(x_train[i, :, :, 0], cmap='gray_r')\n",
        "plt.xticks([]); plt.yticks([])\n",
        "print(y_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "A5qkwPxZR_gn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a Keras Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C1PTavNjXOfh",
        "colab_type": "code",
        "outputId": "c2659962-f2f9-44cb-aa76-bdceaa7c6828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize optimizer and compile model\n",
        "opt = adam(lr = 0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,313,226\n",
            "Trainable params: 1,313,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jmz968qJXlBI",
        "colab_type": "code",
        "outputId": "3bd067c9-8d76-4fdc-f8a9-73d8bd801274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_split=0.3, shuffle=True, verbose=0, epochs=60, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefd875ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "6rjNXRxeYGyw",
        "colab_type": "code",
        "outputId": "2c77c2f8-4d57-4ba4-b8d1-6af3db1f318e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, verbose=1) ###\n",
        "print('Test loss:', loss) ###\n",
        "print('Test accuracy:', acc) ###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 138us/step\n",
            "Test loss: 0.22896832135915757\n",
            "Test accuracy: 0.9199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uAcrUJEBfuY8",
        "colab_type": "code",
        "outputId": "9a02f33c-8fa2-478d-f35d-968bbc72253f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "cell_type": "code",
      "source": [
        "# Ex 3 starts from here\n",
        "\n",
        "# Loading the mnist digits dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "nsamples, width, height = X_train.shape\n",
        "nfeatures = width * height\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "Y_train = keras.utils.to_categorical(Y_train)\n",
        "Y_test = keras.utils.to_categorical(Y_test)\n",
        "ncats = Y_test.shape[1]\n",
        "\n",
        "# Keras model from the lecture at: https://github.com/yoavram/SciComPy/blob/27d1bc656ef925de340bf7e4b0d427b272d9ed17/notebooks/CNN.ipynb\n",
        "model = keras.models.Sequential()\n",
        "model.add(\n",
        "    keras.layers.Reshape(target_shape=(width, height, 1), \n",
        "                         input_shape=(width, height)))\n",
        "model.add(\n",
        "    keras.layers.Conv2D(32, (5, 5)))\n",
        "model.add(\n",
        "    keras.layers.ReLU())\n",
        "model.add(\n",
        "    keras.layers.MaxPool2D())\n",
        "model.add(\n",
        "    keras.layers.Conv2D(64, (5, 5)))\n",
        "model.add(\n",
        "    keras.layers.ReLU())\n",
        "model.add(\n",
        "    keras.layers.MaxPool2D())\n",
        "model.add(\n",
        "    keras.layers.Flatten())\n",
        "model.add(\n",
        "    keras.layers.Dense(1024))\n",
        "model.add(\n",
        "    keras.layers.ReLU())\n",
        "model.add(\n",
        "    keras.layers.Dropout(0.5))\n",
        "model.add(\n",
        "    keras.layers.Dense(ncats))\n",
        "model.add(\n",
        "    keras.layers.Softmax())\n",
        "\n",
        "keras.utils.plot_model(model, to_file='tmp.png')\n",
        "keras.preprocessing.image.load_img('tmp.png')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(), \n",
        "    metrics=[keras.metrics.categorical_accuracy]\n",
        ")\n",
        "\n",
        "history = model.fit(x=X_train, y=Y_train, batch_size=50, epochs=5, \n",
        "    validation_data=(X_test, Y_test),\n",
        ").history\n",
        "\n",
        "model.save('keras_cnn_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax_6 (Softmax)          (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,111,946\n",
            "Trainable params: 1,111,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.1297 - categorical_accuracy: 0.9600 - val_loss: 0.0449 - val_categorical_accuracy: 0.9856\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0436 - categorical_accuracy: 0.9864 - val_loss: 0.0351 - val_categorical_accuracy: 0.9883\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0319 - categorical_accuracy: 0.9899 - val_loss: 0.0292 - val_categorical_accuracy: 0.9905\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0245 - categorical_accuracy: 0.9925 - val_loss: 0.0279 - val_categorical_accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0207 - categorical_accuracy: 0.9937 - val_loss: 0.0265 - val_categorical_accuracy: 0.9920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WgVoOH8aQPUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# releasing the resources\n",
        "del model\n",
        "del X_test\n",
        "del X_train\n",
        "del Y_test\n",
        "del Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4WHZpH7Rbvd",
        "colab_type": "code",
        "outputId": "fe88845b-8942-4bfd-d5dd-0de698553746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "cell_type": "code",
      "source": [
        "# reloading the saved model\n",
        "model = keras.models.load_model('keras_cnn_model.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax_6 (Softmax)          (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,111,946\n",
            "Trainable params: 1,111,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmc4yLyNRylf",
        "colab_type": "code",
        "outputId": "a12f74ad-3e71-49a3-d2db-053620a6303c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "cell_type": "code",
      "source": [
        "# Now we have the model. What needs to be done is listed as follows:\n",
        "# 1.) Make all layers non-trainable\n",
        "# 2.) Pop/Remove the last layer dense and softmax layers\n",
        "# 3.) Add the last dense layer with 10 neurons, and a softmax activation function layer\n",
        "# 4.) Recompile the model\n",
        "\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "model.pop()\n",
        "model.pop()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "=================================================================\n",
            "Total params: 2,213,642\n",
            "Trainable params: 1,111,946\n",
            "Non-trainable params: 1,101,696\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnP3lVsWR3_E",
        "colab_type": "code",
        "outputId": "62a1b1c1-531b-4ecb-da74-16839cef967f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(\n",
        "    keras.layers.Dense(ncats))\n",
        "model.add(\n",
        "    keras.layers.Softmax())\n",
        "# Compile the model here\n",
        "model.compile(\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(), \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax_7 (Softmax)          (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,111,946\n",
            "Trainable params: 10,250\n",
            "Non-trainable params: 1,101,696\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cNKbeTUaUjd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reloading the fashion mnist data again\n",
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "nsamples, width, height = X_train.shape\n",
        "nfeatures = width * height\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "Y_train = keras.utils.to_categorical(Y_train)\n",
        "Y_test = keras.utils.to_categorical(Y_test)\n",
        "ncats = Y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvI8kvXeUx24",
        "colab_type": "code",
        "outputId": "4695ca1b-7008-42d0-87e5-e76e2ef8d49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "# train model here\n",
        "model.fit(x=X_train, y=Y_train, batch_size=50, epochs=5, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.8722 - acc: 0.7147 - val_loss: 0.6921 - val_acc: 0.7711\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.6740 - acc: 0.7705 - val_loss: 0.6237 - val_acc: 0.7974\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.6329 - acc: 0.7817 - val_loss: 0.5947 - val_acc: 0.8012\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.6184 - acc: 0.7857 - val_loss: 0.5794 - val_acc: 0.8075\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.6064 - acc: 0.7893 - val_loss: 0.5651 - val_acc: 0.8092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefd7ed8198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "SRJqbZGbVPbB",
        "colab_type": "code",
        "outputId": "ad022202-e6ce-4940-acf4-971a57237210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test, verbose=1) ###\n",
        "print('Test loss:', loss) ###\n",
        "print('Test accuracy:', acc) ###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 93us/step\n",
            "Test loss: 0.5651335227966309\n",
            "Test accuracy: 0.8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lsYfjx6qWdXw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In Ex 2, the model reached a test accuracy of 0.92 after 60 epochs, and in transfer learning approach, the model got to 0.80 test accuracy after only 5 epochs."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}